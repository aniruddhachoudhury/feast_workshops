### Module 1
This module will focus on understanding key concepts and Feast objects. In this module we will:
 * Deploy a local feature store with a Parquet file offline store and Sqlite online store.
 * Build a training dataset using our time series features from our Parquet files.
 * Materialize feature values from the offline store into the online store.
 * Read the latest features from the online store for inference.


![](images/feast_concepts.png)

A Feast project directory structure, `feature_repo`, it houses all Python files with declarative definitions.
* [Data Source](feature_repo/datasources/filesource.py)
* [Entity](feature_repo/entities/entity.py)
* [Feature](feature_repo/features/feature_views.py)
* [Feast config](feature_repo/feature_store.yaml)

For modularity, I refactored Python files generated by the Feast CLI `feast init feature_repo`. Instead of having
all declarations and definitions in single `.py` file, I have chosen to modularize the directory structure that
maps to each Feast high-level concept and object.

### Setup and Installation

#### Step 1: 
    `conda create --name feast_workshop`
#### Step 2:
    `conda activate feast_workshop`
#### Step 3: 
    `pip install feast`
#### Step 4:
    ` feast version`
    Feast SDK Version: "feast 0.11.0"

### Defining and Declaring your Feast Objects

#### Step 1: Peruse the Python files and 
* Read [Data Source](feature_repo/datasources/filesource.py)
* Read [Entity](feature_repo/entities/entity.py)
* Read [Feature](feature_repo/features/feature_views.py)
* Read [Feast config](feature_repo/feature_store.yaml)

### Step 2: Register feature definitions and deploy your feature store
    `feast apply`
### Step 3: Generating training data
The `feast apply` command builds a training dataset based on the time-series features defined in the 
feature repository [Feature](feature_repo/features/feature_views.py)

    `cd training && python training.py`

